from __future__ import print_function
"""

"""
from pyspark.ml import Pipeline
from pyspark.ml.feature import FeatureHasher
from pyspark.ml.classification import OneVsRest, LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

import pyspark.sql.functions as F
from pyspark.sql import SparkSession

pipeline_path = "output/one_vs_rest_pipeline"
pipeline_model_path = "output/one_vs_rest_pipeline_model"

spark = SparkSession.builder.appName("OneVsRest") \
	.config("spark.dynamicAllocation.enabled", "true") \
	.config("spark.shuffle.service.enabled", "true") \
	.config("spark.serializer", "org.apache.spark.serializer.KryoSerializer") \
	.enableHiveSupport() \
	.getOrCreate()

df = spark.read.table("training")
df.cache()

exclude_cols = ["HasDetections", "MachineIdentifier", "DefaultBrowsersIdentifier", "OrganizationIdentifier", "GeoNameIdentifier", "LocaleEnglishNameIdentifier", "Census_ProcessorCoreCount", "Census_ProcessorClass", "Census_PrimaryDiskTotalCapacity", "Census_PrimaryDiskTypeName", "Census_SystemVolumeTotalCapacity", "Census_HasOpticalDiskDrive", "Census_TotalPhysicalRAM", "Census_InternalPrimaryDiagonalDisplaySizeInInches", "Census_InternalPrimaryDisplayResolutionHorizontal", "Census_InternalBatteryType", "Census_InternalBatteryNumberOfCharges"]
selected_cols = list(set(df.columns) - set(exclude_cols))

print("Selected Features Count: {0}".format(len(selected_cols)))
print("Selected Features: {0}".format(selected_cols))
print("Selected Features without Exclusions Count: {0}".format(len(selected_cols)))

print("Creating Splits")
train, test = df.randomSplit([0.7, 0.3], 51)

print("Building Pipeline")
classifier = LogisticRegression(regParam=0.01, maxIter=100, aggregationDepth=2, fitIntercept=True, family="binomial", elasticNetParam=0.0)
stages = []
stages.append(FeatureHasher(numFeatures=32768, inputCols=selected_cols, outputCol="features", categoricalCols=selected_cols))
stages.append(OneVsRest(classifier=classifier, parallelism=4, featuresCol="features", labelCol="HasDetections", predictionCol="prediction"))
pipeline = Pipeline(stages=stages)

print("Fitting -> Training Data")
pipeline_model = pipeline.fit(train)

print("Fitting -> Test Data")
predictions = pipeline_model.transform(test)
predictions.select("HasDetections", "MachineIdentifier", "prediction").show(truncate=False)

print("Computing Multiclass Accuracy")
evaluator = MulticlassClassificationEvaluator(labelCol="HasDetections", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
print("Test set accuracy = " + str(accuracy))

print("Saving Pipeline")
pipeline.write().overwrite().save(pipeline_path)

print("Saving Pipeline Model")
pipeline_model.write().overwrite().save(pipeline_model_path)

print("Saving Predictions")
predictions.coalesce(5).write.saveAsTable("one_vs_rest_predictions", format="parquet", mode="overwrite")





