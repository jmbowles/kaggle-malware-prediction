from __future__ import print_function
"""

"""
import pickle

from pyspark.ml import Pipeline
from pyspark.ml.feature import FeatureHasher, VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

import pyspark.sql.functions as F

pipeline_model_path = "output/logistic_pipeline_model"

print("Loading and Caching Data")
df = spark.read.load("../datasets/train.csv", format="csv", sep=",", inferSchema="true", header="true")
df.cache()

df = df.replace("requireAdmin", "RequireAdmin", ["SmartScreen"])
df = df.replace("on", "1", ["SmartScreen"])
df = df.replace("On", "1", ["SmartScreen"])
df = df.replace("Enabled", "1", ["SmartScreen"])
df = df.replace("prompt", "Prompt", ["SmartScreen"])
df = df.replace("Promt", "Prompt", ["SmartScreen"])
df = df.replace("00000000", "0", ["SmartScreen"])
df = df.replace("off", "0", ["SmartScreen"])
df = df.replace("OFF", "0", ["SmartScreen"])
df = df.replace("warn", "Warn", ["SmartScreen"])
df = df.fillna("0", ["SmartScreen"])
df = df.fillna(0, ["Census_FirmwareManufacturerIdentifier", "Census_FirmwareVersionIdentifier", "Census_OSBuildNumber", "Census_SystemVolumeTotalCapacity", "Census_InternalBatteryNumberOfCharges", "Census_OSBuildRevision"])
df = df.fillna(9999999, ["Census_PrimaryDiskTotalCapacity"])
df = df.fillna(1000000, ["Census_InternalPrimaryDisplayResolutionHorizontal", "Census_InternalPrimaryDisplayResolutionVertical"])
df = df.withColumn("Derived_AvSigVersion", F.regexp_replace(df.AvSigVersion, r"[^0-9]", "").cast("integer"))
df = df.withColumn("Derived_AppVersion", F.regexp_replace(df.AppVersion, r"[^0-9]", "").cast("integer"))
df = df.withColumn("Derived_EngineVersion", F.regexp_replace(df.EngineVersion, r"[^0-9]", "").cast("integer"))
df = df.withColumn("Derived_OsVer", F.regexp_replace(df.OsVer, r"[^0-9]", "").cast("integer"))
df = df.withColumn("Derived_CensusOSVersion", F.regexp_replace(df.Census_OSVersion, r"[^0-9]", "").cast("integer"))
df = df.withColumn("Derived_Firmware", df.Census_FirmwareManufacturerIdentifier + df.Census_FirmwareVersionIdentifier)
df = df.withColumn("Derived_VolumeCapacity", F.round(df.Census_SystemVolumeTotalCapacity / df.Census_PrimaryDiskTotalCapacity, 2))
df = df.withColumn("Derived_Resolution", df.Census_InternalPrimaryDisplayResolutionHorizontal * df.Census_InternalPrimaryDisplayResolutionVertical)

exclude_cols = ["HasDetections", "MachineIdentifier", "AvSigVersion", "AppVersion", "EngineVersion", "OsVer", "Census_OSVersion", "Census_FirmwareManufacturerIdentifier", "Census_FirmwareVersionIdentifier", "Census_SystemVolumeTotalCapacity", "Census_PrimaryDiskTotalCapacity", "Census_InternalPrimaryDisplayResolutionHorizontal", "Census_InternalPrimaryDisplayResolutionVertical", "CityIdentifier", "AutoSampleOptIn", "LocaleEnglishNameIdentifier", "DefaultBrowsersIdentifier", "PuaMode", "Census_IsFlightingInternal", "OrganizationIdentifier", "GeoNameIdentifier", "LocaleEnglishNameIdentifier", "Census_ProcessorClass", "Census_PrimaryDiskTypeName", "Census_InternalBatteryType"]
derived = ["Derived_AvSigVersion", "Derived_AppVersion", "Derived_EngineVersion", "Derived_OsVer", "Derived_CensusOSVersion", "Derived_Firmware", "Derived_VolumeCapacity", "Derived_Resolution"]
continuous_cols = ["Census_OSBuildNumber", "AVProductStatesIdentifier", "AVProductsInstalled", "OsBuild", "OsSuite", "IeVerIdentifier", "Census_ProcessorCoreCount", "Census_TotalPhysicalRAM", "Census_InternalBatteryNumberOfCharges", "Census_OSBuildRevision"] + derived
categorical_cols = list(set(df.columns) - set(exclude_cols) - set(continuous_cols)) 
feature_cols = ["categorical_features"] + continuous_cols

print("Creating Splits")
train, test = df.randomSplit([0.7, 0.3])

print("Selected Features Count: {0}".format(len(feature_cols)))
print("Selected Features: {0}".format(feature_cols))

print("Building Pipeline")
hasher = FeatureHasher(inputCols=categorical_cols, outputCol="categorical_features", categoricalCols=categorical_cols)
features = VectorAssembler(inputCols=feature_cols, outputCol="features", handleInvalid="skip")
regression = LogisticRegression(featuresCol="features", labelCol="HasDetections", regParam=0.0, elasticNetParam=0.0, tol=1e-06, threshold=0.5, family="auto")
pipeline = Pipeline(stages=[hasher, features, regression])
evaluator = MulticlassClassificationEvaluator(labelCol="HasDetections", predictionCol="prediction", metricName="accuracy")

print("Configuring CrossValidation")
params = ParamGridBuilder() \
			.addGrid(hasher.numFeatures, [262144]) \
			.addGrid(regression.fitIntercept, [True]) \
			.addGrid(regression.maxIter, [200]) \
			.addGrid(regression.standardization, [False]) \
			.build()

validator = CrossValidator(estimator=pipeline,
                          estimatorParamMaps=params,
                          evaluator=evaluator,
                          numFolds=2)

print("Fitting -> Training Data")
pipeline_model = validator.fit(train)

print("Fitting -> Test Data")
predictions = pipeline_model.transform(test)
predictions.select("HasDetections", "MachineIdentifier", "probability", "prediction").show(truncate=False)

print("Computing Accuracy")
accuracy = evaluator.evaluate(predictions)
print("Test set accuracy = {0}".format(accuracy))

print("Saving Pipeline Model")
pipeline_model.bestModel.write().overwrite().save(pipeline_model_path)

#print("Saving Predictions")
#predictions.write.saveAsTable("logistic_predictions", format="parquet", mode="overwrite", path="output/tables/logistic/predictions")






