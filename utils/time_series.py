from __future__ import print_function
"""

"""
import numpy as np
import pandas as pd

import pyspark.sql.functions as F
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType


spark = SparkSession.builder \
	.appName("TimeSeries") \
	.config("spark.sql.execution.arrow.enabled", "true") \
	.config("spark.dynamicAllocation.enabled", "true") \
	.config("spark.shuffle.service.enabled", "true") \
	.config("spark.serializer", "org.apache.spark.serializer.KryoSerializer") \
	.enableHiveSupport() \
	.getOrCreate()

schema_signatures = StructType([StructField("AvSigVersion", StringType(), False), StructField("AvSigVersionDate", StringType(), False)])
schema_os = StructType([StructField("OSVersion", StringType(), False), StructField("OSVersionDate", StringType(), False)])

print("Loading Data")
data_signatures = np.load('../datasets/AvSigVersionTimestamps.npy')[()]
data_os = np.load('../datasets/OSVersionTimestamps.npy')[()]

print("Converting Data")
pdf_signatures = pd.concat([pd.DataFrame([(k, v.isoformat())], columns=['AvSigVersion', 'AvSigVersionDate']) for _, (k, v) in enumerate(data_signatures.items())], ignore_index=True)
pdf_os = pd.concat([pd.DataFrame([(k, v.isoformat())], columns=['OSVersion', 'OSVersionDate']) for _, (k, v) in enumerate(data_os.items())], ignore_index=True)


print("Creating Spark Dataframes")
df_signatures = spark.createDataFrame(pdf_signatures, schema_signatures)
df_signatures = df_signatures.withColumn("AvSigVersionUTC", F.from_utc_timestamp(df_signatures.AvSigVersionDate, "UTC"))
df_signatures = df_signatures.drop(df_signatures.AvSigVersionDate)

df_os = spark.createDataFrame(pdf_os, schema_os)
df_os = df_os.withColumn("OSVersionUTC", F.from_utc_timestamp(df_os.OSVersionDate, "UTC"))
df_os = df_os.drop(df_os.OSVersionDate)

df_signatures.coalesce(1).write.parquet(path="../datasets/avsigversion_timestamps", mode="overwrite")
df_os.coalesce(1).write.parquet(path="../datasets/osversion_timestamps", mode="overwrite")