from __future__ import print_function
"""

"""
import numpy as np
import pandas as pd

import pyspark.sql.functions as F
from pyspark.sql import SparkSession
from pyspark.sql.window import Window


spark = SparkSession.builder \
	.appName("AvSignature TimeSeries") \
	.config("spark.sql.execution.arrow.enabled", "true") \
	.config("spark.dynamicAllocation.enabled", "true") \
	.config("spark.shuffle.service.enabled", "true") \
	.enableHiveSupport() \
	.getOrCreate()


print("Loading and Caching Data")
df_signatures = spark.read.parquet("../datasets/avsigversion_timestamps")
df_os = spark.read.parquet("../datasets/osversion_timestamps")
df = spark.read.table("training")
df = df.join(df_signatures, "AvSigVersion")
df = df.join(df_os, "Census_OSVersion")
df.cache()

places = Window.partitionBy("AvSigVersion", "Wdft_RegionIdentifier", "CountryIdentifier")
detections = Window.partitionBy("HasDetections", "Wdft_RegionIdentifier", "AvSigVersion", "CountryIdentifier")
total_detections = F.count("HasDetections").over(places)
detection = F.count("HasDetections").over(detections)

df1 = df.withColumn("total_detections", total_detections) \
		.withColumn("count_0", F.when(F.expr("HasDetections == 0"), detection).otherwise(total_detections - detection)) \
		.withColumn("count_1", total_detections - F.col("count_0"))
#df1 = df1.select("HasDetections", "AvSigVersion", "AvSigVersionUTC", "Wdft_RegionIdentifier", "CountryIdentifier", "total_detections", "count_0", "count_1").orderBy("AvSigVersionUTC", "Wdft_RegionIdentifier", "CountryIdentifier", "HasDetections")
#df1.show()

selected_cols = ["AvSigVersion", "AvSigVersionUTC", "OSVersionUTC", "Wdft_RegionIdentifier", "CountryIdentifier", "total_detections", "count_0", "count_1"]
df1 = df1.select(*selected_cols)
df1 = df1.withColumn("AvSigVersionUTC_Hour", F.date_trunc("hour", df1.AvSigVersionUTC))
df1 = df1.withColumn("OSVersionUTC_Hour", F.date_trunc("hour", df1.OSVersionUTC))
df1 = df1.distinct().orderBy("AvSigVersionUTC_Hour").select(*selected_cols)
df1.show(1000)
#df1 = df1.where(df1.total_detections >= 100).distinct().orderBy("AvSigVersionUTC_Hour", "OSVersionUTC_Hour").select(*selected_cols).show(1000)