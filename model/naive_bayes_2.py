from __future__ import print_function
"""
Bayes Rule:

P(Malware | X) = P(X | Malware) P(Malware) / P(X)

Where X = 83 column values in each dataset:
"""
import pickle

from pyspark.sql.types import DoubleType
from pyspark.ml import Pipeline
from pyspark.ml.feature import ChiSqSelectorModel, StringIndexer, VectorAssembler, OneHotEncoderEstimator, FeatureHasher
from pyspark.ml.classification import NaiveBayes
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

import pyspark.sql.functions as F

pipeline_path = "output/naive_bayes_pipeline"
pipeline_model_path = "output/naive_bayes_pipeline_model"

chi_model_path = "../explore/output/chi_model"
feature_path = "../explore/output/features.pkl"

feature_cols = None
model = None

try:
	model = ChiSqSelectorModel.load(chi_model_path)

	with open(feature_path, "rb") as f:
		feature_cols = pickle.load(f)
except:
	print("WARN: Output path missing")

#selected_cols = [feature_cols[i] for i in model.selectedFeatures]
#selected_cols = ["Platform", "AvSigVersion", "AVProductStatesIdentifier", "CountryIdentifier", "Wdft_RegionIdentifier", "OsBuildLab", "SkuEdition", "Census_PowerPlatformRoleName", "Census_OSVersion", "Census_OSInstallLanguageIdentifier", "Census_OSBranch"]
selected_cols = ["Platform", "AvSigVersion", "AVProductStatesIdentifier", "CountryIdentifier", "SMode", "Wdft_RegionIdentifier", "Census_OSVersion", "OsBuildLab", "Census_IsTouchEnabled", "Census_IsPenCapable", "Census_IsSecureBootEnabled"]

print("Selected Features Count: {0}".format(len(selected_cols)))
print("Selected Features: {0}".format(selected_cols))

df = spark.read.load("../datasets/train.csv", format="csv", sep=",", inferSchema="true", header="true")
df.cache()

#df_os = df.rollup("Platform", "AvSigVersion", "Census_OSVersion", "HasDetections").count().where(F.expr("HasDetections is not null and count > 10000")).select("Census_OSVersion").distinct()
#df_country = df.rollup("Platform", "AvSigVersion", "Census_OSVersion", "CountryIdentifier", "HasDetections").count().where(F.expr("HasDetections is not null and count > 100")).select("CountryIdentifier").distinct()
#df = df.join(df_os, "Census_OSVersion")
#df = df.join(df_country, "CountryIdentifier")

label_col = ["HasDetections"]
meta_cols = ["MachineIdentifier"]
#exclude_cols = ["Wdft_RegionIdentifier", "Census_ProcessorManufacturerIdentifier", "Census_OSUILocaleIdentifier", "DefaultBrowsersIdentifier", "OrganizationIdentifier", "GeoNameIdentifier", "LocaleEnglishNameIdentifier", "Census_ProcessorCoreCount", "Census_ProcessorClass", "Census_PrimaryDiskTotalCapacity", "Census_PrimaryDiskTypeName", "Census_SystemVolumeTotalCapacity", "Census_HasOpticalDiskDrive", "Census_TotalPhysicalRAM", "Census_InternalPrimaryDiagonalDisplaySizeInInches", "Census_InternalPrimaryDisplayResolutionHorizontal", "Census_InternalBatteryType", "Census_InternalBatteryNumberOfCharges"]
exclude_cols = []
model_cols = list(set(selected_cols) - set(exclude_cols))

print("Selected Features without Exclusions Count: {0}".format(len(model_cols)))

print("Creating Splits")
train, test = df.randomSplit([0.6, 0.4], 51)

print("Building Pipeline")
stages = []
stages.append(FeatureHasher(numFeatures=32768, inputCols=selected_cols, outputCol="features", categoricalCols=selected_cols))
stages.append(NaiveBayes(smoothing=1.0, featuresCol="features", labelCol="HasDetections", predictionCol="prediction", modelType="multinomial"))
pipeline = Pipeline(stages=stages)

print("Fitting -> Training Data")
pipeline_model = pipeline.fit(train)

print("Fitting -> Test Data")
predictions = pipeline_model.transform(test)
predictions.select("HasDetections", "MachineIdentifier", "probability", "prediction").show(truncate=False)

print("Computing Multiclass Accuracy")
evaluator = MulticlassClassificationEvaluator(labelCol="HasDetections", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
print("Test set accuracy = " + str(accuracy))

print("Saving Pipeline")
pipeline.write().overwrite().save(pipeline_path)

print("Saving Pipeline Model")
pipeline_model.write().overwrite().save(pipeline_model_path)

#print("Saving Predictions")
#predictions.write.saveAsTable("naive_bayes_predictions", format="parquet", mode="overwrite", path="output/tables/naive_bayes/predictions")




