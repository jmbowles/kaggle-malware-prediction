from __future__ import print_function
"""
Bayes Rule:

P(Malware | X) = P(X | Malware) P(Malware) / P(X)

Where X = 83 column values in each dataset:
"""
import pickle

from pyspark.sql import Window
from pyspark.ml import Pipeline
from pyspark.ml.feature import FeatureHasher
from pyspark.ml.classification import NaiveBayes
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

import pyspark.sql.functions as F

pipeline_model_path = "output/naive_bayes_pipeline_model"

#selected_cols = ["Platform", "AvSigVersion", "AVProductStatesIdentifier", "CountryIdentifier", "SMode", "Wdft_RegionIdentifier", "Census_OSVersion", "OsBuildLab", "Census_IsTouchEnabled", "Census_IsPenCapable", "Census_IsSecureBootEnabled"]
#selected_cols = ["Platform", "AvSigVersion", "AVProductStatesIdentifier", "CountryIdentifier", "Census_OSVersion", "Derived_Firmware", "Derived_Processor", "Derived_Installer", "Derived_AV", "Derived_Grouping", "Census_IsTouchEnabled", "Census_IsSecureBootEnabled"]
print("Loading and Caching Data")
df = spark.read.load("../datasets/train.csv", format="csv", sep=",", inferSchema="true", header="true")
df.cache()

df = df.withColumn("Derived_Firmware", F.concat(df.Census_FirmwareManufacturerIdentifier, F.lit("_"), df.Census_FirmwareVersionIdentifier))
df = df.replace("requireAdmin", "RequireAdmin", ["SmartScreen"])
df = df.replace("on", "1", ["SmartScreen"])
df = df.replace("On", "1", ["SmartScreen"])
df = df.replace("Enabled", "1", ["SmartScreen"])
df = df.replace("prompt", "Prompt", ["SmartScreen"])
df = df.replace("Promt", "Prompt", ["SmartScreen"])
df = df.replace("00000000", "0", ["SmartScreen"])
df = df.replace("off", "0", ["SmartScreen"])
df = df.replace("OFF", "0", ["SmartScreen"])
df = df.replace("warn", "Warn", ["SmartScreen"])
df = df.fillna("0", ["SmartScreen"])


#df = df.withColumn("Derived_Processor", F.concat(df.Census_ProcessorManufacturerIdentifier, F.lit("_"), df.Census_ProcessorModelIdentifier))
#df = df.withColumn("Derived_Installer", F.concat(df.Census_OSInstallTypeName, F.lit("_"), df.Census_OSInstallLanguageIdentifier))

exclude_cols = ["HasDetections", "MachineIdentifier", "DefaultBrowsersIdentifier", "OrganizationIdentifier", "GeoNameIdentifier", "LocaleEnglishNameIdentifier", "Census_ProcessorCoreCount", "Census_ProcessorClass", "Census_PrimaryDiskTotalCapacity", "Census_PrimaryDiskTypeName", "Census_SystemVolumeTotalCapacity", "Census_HasOpticalDiskDrive", "Census_TotalPhysicalRAM", "Census_InternalPrimaryDiagonalDisplaySizeInInches", "Census_InternalPrimaryDisplayResolutionHorizontal", "Census_InternalBatteryType", "Census_InternalBatteryNumberOfCharges"]
#selected_cols = list(set(df.columns) - set(exclude_cols))
selected_cols = ["SmartScreen", "Derived_Firmware", "Census_ProcessorModelIdentifier", "AVProductStatesIdentifier", "AvSigVersion", "Census_OSVersion"]

print("Selected Features Count: {0}".format(len(selected_cols)))
print("Selected Features: {0}".format(selected_cols))

'''
df = df.withColumn("Derived_Firmware", F.concat(df.Census_FirmwareManufacturerIdentifier, F.lit("_"), df.Census_FirmwareVersionIdentifier))
df = df.withColumn("Derived_Processor", F.concat(df.Census_ProcessorManufacturerIdentifier, F.lit("_"), df.Census_ProcessorModelIdentifier))
df = df.withColumn("Derived_Installer", F.concat(df.Census_OSInstallTypeName, F.lit("_"), df.Census_OSInstallLanguageIdentifier))
df = df.withColumn("Derived_AV", F.concat(df.AppVersion, F.lit("_"), df.AvSigVersion))
df = df.withColumn("Derived_Grouping", F.concat(df.Derived_Firmware, F.lit("_"), df.Derived_Processor, F.lit("_"), df.Derived_AV))

window_sku = Window.partitionBy("SkuEdition")
window_sku_detections = Window.partitionBy("SkuEdition", "HasDetections")
sku_count = F.count(df.HasDetections).over(window_sku_detections)
sku_total = F.count(df.HasDetections).over(window_sku)
sku_0 = F.when(df.HasDetections==0, sku_count).otherwise(sku_total - sku_count)
sku_1 = sku_total - sku_0
df.select("HasDetections", "MachineIdentifier", "SkuEdition", sku_total.alias("sku_total"), sku_0.alias("SkuEdition_0"), sku_1.alias("SkuEdition_1")).show(truncate=False)

#df.select("SkuEdition_total", "SkuEdition_0", "SkuEdition_1").show(truncate=False)


df.crosstab("HasDetections", "SkuEdition").show()
df.select("HasDetections", "MachineIdentifier", "SkuEdition", sku_total.alias("sku_total"), sku_0.alias("SkuEdition_0"), sku_1.alias("SkuEdition_1")).select("SkuEdition", "SkuEdition_0").distinct().show(truncate=False)
df.select("HasDetections", "MachineIdentifier", "SkuEdition", sku_total.alias("sku_total"), sku_0.alias("SkuEdition_0"), sku_1.alias("SkuEdition_1")).select("SkuEdition", "SkuEdition_1").distinct().show(truncate=False)
'''

'''
count_columns = []

for column_name in selected_cols:
	window_column = Window.partitionBy(column_name)
	window_column_detections = Window.partitionBy(column_name, "HasDetections")
	class_values = F.count(df.HasDetections).over(window_column_detections)
	total_values = F.count(df.HasDetections).over(window_column)
	label_0 = F.when(df.HasDetections==0, class_values).otherwise(total_values - class_values)
	label_1 = total_values - label_0
	column_total = column_name + "_total"
	column_label_0 = column_name + "_0"
	column_label_1 = column_name + "_1"
	count_columns.append(column_total)
	count_columns.append(column_label_0)
	count_columns.append(column_label_1)
	df = df.withColumn(column_total, total_values.alias(""))
	df = df.withColumn(column_label_0, label_0)
	df = df.withColumn(column_label_1, label_1)

meta_columns = ["HasDetections", "MachineIdentifier"]

df = df.select(*(meta_columns + count_columns))

'''
print("Creating Splits")
train, test = df.randomSplit([0.7, 0.3])

print("Building Pipeline")
hasher = FeatureHasher(numFeatures=32768, inputCols=selected_cols, outputCol="features", categoricalCols=selected_cols)
evaluator = MulticlassClassificationEvaluator(labelCol="HasDetections", predictionCol="prediction", metricName="accuracy")
stages = []
stages.append(hasher)
stages.append(NaiveBayes(smoothing=1.0, featuresCol="features", labelCol="HasDetections", predictionCol="prediction", modelType="multinomial"))
pipeline = Pipeline(stages=stages)

print("Configuring CrossValidation")
params = ParamGridBuilder() \
			.addGrid(hasher.numFeatures, [16384, 32768]) \
			.build()

validator = CrossValidator(estimator=pipeline,
                          estimatorParamMaps=params,
                          evaluator=evaluator,
                          numFolds=3)

print("Fitting -> Training Data")
pipeline_model = validator.fit(train)

print("Fitting -> Test Data")
predictions = pipeline_model.transform(test)
predictions.select("HasDetections", "MachineIdentifier", "probability", "prediction").show(truncate=False)

print("FeatureHasher.numFeatures = {0}".format(stages[0].getNumFeatures()))
stages[0].getNumFeatures()

print("Computing Accuracy")
accuracy = evaluator.evaluate(predictions)
print("Test set accuracy = {0}".format(accuracy))

print("Saving Pipeline Model")
pipeline_model.bestModel.write().overwrite().save(pipeline_model_path)

#print("Saving Predictions")
#predictions.write.saveAsTable("naive_bayes_predictions", format="parquet", mode="overwrite", path="output/tables/naive_bayes/predictions")






